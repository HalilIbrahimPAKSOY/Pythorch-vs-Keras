# -*- coding: utf-8 -*-
"""pythorch fashion mnıst.ipynb adlı dosyanın kopyası

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1__n96v1RrxcXEwsg71jMzoVefN_AuV77
"""

#kütüphaneyi içe aktaralım
import torch

import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import torch.nn as nn
import torch.optim as optim
print("GPU available: {}".format(torch.cuda.is_available()))

if torch.cuda.is_available():
  device = 'cuda' 
else:
  device = 'cpu'

# Bir PyTorch tensörlerine dönüştürün ve değerimizi -1 ile +1 arasında normalleştirin
transform = transforms.Compose([transforms.ToTensor(),
                               transforms.Normalize((0.5, ), (0.5, )) ])

"""**3. Torchvision kullanarak COuntry Veri Kümemizi getirin**

Birçok çevrimiçi öğretici durum dönüşümleri, yükleme sırasında uygulanır. Bu doğru değil. Transformatörler yalnızca Veri Yükleyicimiz tarafından yüklendiğinde uygulanır.

Veri kümemiz değişmeden bırakılır, yalnızca Veri Yükleyicimiz tarafından yüklenen görüntü grupları her yinelemede kopyalanır ve dönüştürülür.

Torchvision aracılığıyla erişilebilen diğer veri kümelerini buradan görüntüleyin - https://pytorch.org/vision/stable/datasets.html
"""

#Eğitim Verilerimizi yükleyin ve yüklerken hangi dönüşümün kullanılacağını belirtin
#MNIST bir veri kümesidir 
trainset = torchvision.datasets.FashionMNIST('mnist', 
                                      train = True, 
                                      download = True,
                                      transform = transform)
#Test Verilerimizi yükleyin ve yüklerken hangi dönüşümün kullanılacağını belirtin
testset = torchvision.datasets.FashionMNIST('mnist', 
                                     train = False,
                                     download = True,
                                     transform = transform)

#Eğitim verilerimiz için 60.000 Görüntü örneğimiz ve test verilerimiz için 10.000 Görüntü örneğimiz var
#her biri 28 x 28 piksel, gri tonlamalı oldukları için görüntümüzün 3. boyutu yoktur.
print(trainset.data.shape)
print(testset.data.shape)

#Bu, veri kümemizdeki ilk değerdir.
print(trainset.data[0].shape)
print(trainset.data[0])

import cv2
import numpy as np
from matplotlib import pyplot as plt

# imshow fonksiyonumuzu tanımlayın 
def imgshow(title="", image = None, size = 6):
    w, h = image.shape[0], image.shape[1]
    aspect_ratio = w/h
    plt.figure(figsize=(size * aspect_ratio,size))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.show()

# Convert image to a numpy array
image = trainset.data[0].numpy()
imgshow("FashionMNIST Sample", image)

"""**Alternatif olarak, veri kümemizden birçok örneği göstermek için matplotlib'i kullanabiliriz.**"""

#MNIST eğitim veri setinin ilk 50 görüntüsünü görelim
import matplotlib.pyplot as plt

figure = plt.figure()
num_of_images = 50 

for index in range(1, num_of_images + 1):
    plt.subplot(5, 10, index)
    plt.axis('off')
    plt.imshow(trainset.data[index], cmap='gray_r')

#Treni hazırlayın ve yükleyiciyi test edin
#shuffle verileri rasgele karıştırıyor
trainloader = torch.utils.data.DataLoader(trainset,
                                           batch_size = 128,
                                           shuffle = True,
                                           num_workers = 0)

testloader = torch.utils.data.DataLoader(testset,
                                          batch_size = 128,
                                          shuffle = False,
                                          num_workers = 0)

"""**Toplu yükleme için Iter ve Next() kullanma**"""

#Train_loader nesnemiz için bir yineleyici döndürmek üzere Python işlevini iter kullanıyoruz
dataiter = iter(trainloader)
# Yineleyicimizden ilk veri yığınını almak için next'i kullanırız
images, labels = next(dataiter)

print(images.shape)
print(labels.shape)

import matplotlib.pyplot as plt
import numpy as np

# function to show an image
def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

#bazı rastgele eğitim görüntüleri alın
dataiter = iter(trainloader)
images, labels = next(dataiter)

# show images
imshow(torchvision.utils.make_grid(images))

# print labels
print(''.join('%1s' % labels[j].numpy() for j in range(128)))

import torch.nn as nn
import torch.nn.functional as F #

#Bir Python Sınıfı Kullanarak Modelimizi Oluşturun
class Net(nn.Module):
    def __init__(self):
        # super, nn.Module'ün bir alt sınıfıdır ve tüm yöntemlerini devralır
        super(Net, self).__init__()

        # Burada katman nesnelerimizi tanımlıyoruz.
        # 1 adım ve 0 dolgu ile 3x3 boyutunda 32 Filtre kullanan ilk CNN Katmanımız
        self.conv1 = nn.Conv2d(1, 32, 3)
        # 1 adım ve 0 dolgu ile 3x3 boyutunda 64 Filtre kullanan ikinci CNN Katmanımız
        self.conv2 = nn.Conv2d(32, 64, 3)
        # Maksimum Havuz Katmanımız 2 x 2 adım 2 çekirdeği
        self.pool = nn.MaxPool2d(2, 2)
        # İlk Tamamen Bağlı Katmanımız (Doğrusal olarak adlandırılır), Max Pool'umuzun çıktısını alır
        # 12 x 12 x 64 olan ve onu 128 düğüm kümesine bağlayan
        self.fc1 = nn.Linear(64 * 12 * 12, 128)
        # İkinci Tam Bağlantılı Katmanımız, 128 düğümü 10 çıkış düğümüne (sınıflarımız) bağlar
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        # burada ileri yayılım dizimizi tanımlıyoruz
        # Dönüşüm1 - Relu - Dönüşüm2 - Relu - Maks Havuz - Düzleştirme - FC1 - FC2 olduğunu unutmayın
        x = F.relu(self.conv1(x))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 12 * 12) # Flatten
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Modelin bir örneğini oluşturun ve onu (bellek ve işlemler) CUDA cihazına taşıyın
net = Net()
net.to(device)

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3)
        self.conv2 = nn.Conv2d(32, 64, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 12 * 12, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 12 * 12)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

net = Net()
net.to(device)

print(net)

# We import our optimizer function
import torch.optim as optim

# Kayıp fonksiyonumuz olarak Çapraz Entropi Kaybını kullanıyoruz
criterion = nn.CrossEntropyLoss()

# Gradyan iniş algoritmamız veya Optimize Edici için
# 0,001 öğrenme oranıyla Stokastik Gradient Descent (SGD) kullanıyoruz
# Momentumu 0,9 olarak ayarladık
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

# Eğitim veri kümesi üzerinde birden çok kez döngü yaparız (her seferinde bir dönem olarak adlandırılır)
epochs = 10

# günlükleri depolamak için bazı boş diziler oluşturun
epoch_log = []
loss_log = []
accuracy_log = []

# Belirtilen sayıda dönem için yineleme yapın
for epoch in range(epochs):  
    print(f'Starting Epoch: {epoch+1}...')

    # Running_loss'daki her mini partiden sonra kaybımızı eklemeye veya biriktirmeye devam ediyoruz
    running_loss = 0.0

    # Trainloader yineleyicimizi yineliyoruz
    # Her döngü bir mini partidir
    for i, data in enumerate(trainloader, 0):
        # girdileri alın; veriler [girişler, etiketler] listesidir
        inputs, labels = data

        # Move our data to GPU
        inputs = inputs.to(device)
        labels = labels.to(device)

        # Sıfıra ayarlayarak antrenmandan önce eğimleri temizleyin
        # Yeni bir başlangıç için gerekli
        optimizer.zero_grad()

        # Forward -> backprop + optimize
        outputs = net(inputs) # Forward Propagation 
        loss = criterion(outputs, labels) # Kayıp Alın (sonuçlar ve tahminler arasındaki farkı ölçün)
        loss.backward() # Tüm düğümler için yeni gradyanları elde etmek için geri yayma
        optimizer.step() # Update the gradients/weights

        # Print Training statistics - Epoch/Iterations/Loss/Accuracy
        #Eğitim istatistiklerini yazdır - Dönem/Yinelemeler/Kayıp/Doğruluk
        running_loss += loss.item()
        if i % 50 == 49:    # show our loss every 50 mini-batches,her 50 mini partide bir kaybımız nasıl
            correct = 0 # Initialize our variable to hold the count for the correct predictions,Doğru tahminlerin sayısını tutmak için değişkenimizi başlat
            total = 0 # Initialize our variable to hold the count of the number of labels iterated,Yinelenen etiket sayısını tutmak için değişkenimizi başlat

            # We don't need gradients for validation, so wrap in , Doğrulama için gradyanlara ihtiyacımız yok, bu yüzden sarın
            # no_grad to save memory,hafızadan tasarruf etmek için no_grad
            with torch.no_grad():
                # Iterate through the testloader iterator,Testloader yineleyici aracılığıyla yineleyin
                for data in testloader:
                    images, labels = data
                    # Move our data to GPU,Verilerimizi GPU'ya taşıyın
                    images = images.to(device)
                    labels = labels.to(device)
                    
                    # Foward propagate our test data batch through our model,Test veri grubumuzun modelimiz aracılığıyla ileriye doğru yayılması
                    outputs = net(images)

                     # Get predictions from the maximum value of the predicted output tensor,Öngörülen çıkış tensörünün maksimum değerinden tahminler alın
                     # we set dim = 1 as it specifies the number of dimensions to reduce,azaltılacak boyut sayısını belirttiği için dim = 1 olarak ayarladık
                    _, predicted = torch.max(outputs.data, dim = 1)
                    # Keep adding the label size or length to the total variable,Etiket boyutunu veya uzunluğunu toplam değişkene eklemeye devam edin
                    total += labels.size(0)
                    # Keep a running total of the number of predictions predicted correctly,Doğru tahmin edilen tahminlerin sayısının sürekli bir toplamını tutun
                    correct += (predicted == labels).sum().item()

                accuracy = 100 * correct / total
                epoch_num = epoch + 1
                actual_loss = running_loss / 50
                print(f'Epoch: {epoch_num}, Mini-Batches Completed: {(i+1)}, Loss: {actual_loss:.3f}, Test Accuracy = {accuracy:.3f}%')
                running_loss = 0.0

    # Store training stats after each epoch,Her dönemden sonra eğitim istatistiklerini saklayın
    epoch_log.append(epoch_num)
    loss_log.append(actual_loss)
    accuracy_log.append(accuracy)

print('Finished Training')

PATH = './mnist_cnn_net.pth'
torch.save(net.state_dict(), PATH)

# Loading one mini-batch
dataiter = iter(testloader)
images, labels = next(dataiter)

# Display images using torchvision's utils.make_grid()
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ',''.join('%1s' % labels[j].numpy() for j in range(128)))

# Create an instance of the model and move it (memory and operations) to the CUDA device.
#Modelin bir örneğini oluşturun ve onu (bellek ve işlemler) CUDA cihazına taşıyın
net = Net()
net.to(device)

# Load weights from the specified path
#Ağırlıkları belirtilen yoldan yükle
net.load_state_dict(torch.load(PATH))

## Let's forward propagate one mini-batch and get the predicted outputs
#Bir mini partiyi iletelim ve tahmin edilen çıktıları alalım
# We use the Python function iter to return an iterator for our train_loader object
#Train_loader nesnemiz için bir yineleyici döndürmek üzere Python işlevini iter kullanıyoruz
test_iter = iter(testloader)

# We use next to get the first batch of data from our iterator
#İteratörümüzden ilk veri grubunu almak için next'i kullanırız.
images, labels = next(test_iter)

# Move our data to GPU
images = images.to(device)
labels = labels.to(device)

outputs = net(images)

# Get the class predictions using torch.max
#Torch.max kullanarak sınıf tahminlerini alın
_, predicted = torch.max(outputs, 1)

# Print our 128 predictions
print('Predicted: ', ''.join('%1s' % predicted[j].cpu().numpy() for j in range(128)))

correct = 0 
total = 0

with torch.no_grad():
    for data in testloader:
        images, labels = data
        # Move our data to GPU
        images = images.to(device)
        labels = labels.to(device)
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f'Accuracy of the network on the 10000 test images: {accuracy:.3}%')

# To create a plot with secondary y-axis we need to create a subplot
#İkincil y eksenine sahip bir grafik oluşturmak için bir alt grafik oluşturmamız gerekir.
fig, ax1 = plt.subplots()

# Set title and x-axis label rotation
#Başlığı ve x ekseni etiket dönüşünü ayarla
plt.title("Accuracy & Loss vs Epoch")
plt.xticks(rotation=45)

# We use twinx to create a plot a secondary y axis
#İkincil bir y ekseni çizmek için twinx kullanıyoruz
ax2 = ax1.twinx()

# Create plot for loss_log and accuracy_log
#kayıp_log ve doğruluk_log için grafik oluştur
ax1.plot(epoch_log, loss_log, 'g-')
ax2.plot(epoch_log, accuracy_log, 'b-')

# Set labels
#Etiketleri ayarla
ax1.set_xlabel('Epochs')
ax1.set_ylabel('Loss', color='g')
ax2.set_ylabel('Test Accuracy', color='b')

plt.show()

epoch_log = list(range(1,11))
epoch_log

class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))

# We don't need gradients for validation, so wrap in
#Doğrulama için gradyanlara ihtiyacımız yok, bu yüzden sarın 
# no_grad to save memory
#hafızadan tasarruf etmek için no_grad
with torch.no_grad():
    for data in testloader:
        images, labels = data

        # Move our data to GPU
        images = images.to(device)
        labels = labels.to(device)

        # Get our outputs
        outputs = net(images)

        # use torch.max() to get the predicted class for the first dim of our batch
        #Partimizin ilk karartması için tahmin edilen sınıfı elde etmek için torch.max() kullanın
        # note this is just the first 16 data points/images of our batch of 128 images
        #bunun 128 görüntüden oluşan grubumuzun yalnızca ilk 16 veri noktası/görüntü olduğunu unutmayın 
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        
        for i in range(15):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1


for i in range(10):
    class_accuracy = 100 * class_correct[i] / class_total[i]
    print(f'Accuracy of {i} : {class_accuracy:.3f}%')

c

net.eval()

# We don't need gradients for validation, so wrap in 
# no_grad to save memory
with torch.no_grad():
    for data in testloader:
        images, labels = data

        # Move our data to GPU
        images = images.to(device)
        labels = labels.to(device)

        # Get our outputs
        outputs = net(images)

        # use torch.argmax() to get the predictions, argmax is used for long_tensors
        #tahminleri almak için torch.argmax() kullanın, argmax long_tensors için kullanılır
        predictions = torch.argmax(outputs, dim=1)

        # For test data in each batch we identify when predictions did not match the label
        #Her gruptaki test verileri için, tahminlerin etiketle eşleşmediğini belirleriz
        # then we print out the actual ground truth 
        #sonra gerçek temel gerçeği yazdırırız
        for i in range(data[0].shape[0]):
            pred = predictions[i].item()
            label = labels[i]
            if(label != pred):
                print(f'Actual Label: {pred}, Predicted Label: {label}')       
                img = np.reshape(images[i].cpu().numpy(),[28,28])
                imgshow("", np.uint8(img), size = 1)

"""Etiketler
Her eğitim ve test örneği, aşağıdaki etiketlerden birine atanır:

Etiket	Açıklama

0	tişört/üst

1	pantolon

2	kazak

3	Elbise

4	Kaplamak

5	Sandalet

6	Gömlek

7	Spor ayakkabı

8	Çanta

9	Bilek boyu bot
"""

nb_classes = 10

confusion_matrix = torch.zeros(nb_classes, nb_classes)

with torch.no_grad():
    for i, (inputs, classes) in enumerate(testloader):
        inputs = inputs.to(device)
        classes = classes.to(device)
        outputs = net(inputs)
        _, preds = torch.max(outputs, 1)
        for t, p in zip(classes.view(-1), preds.view(-1)):
                confusion_matrix[t.long(), p.long()] += 1

print(confusion_matrix)

